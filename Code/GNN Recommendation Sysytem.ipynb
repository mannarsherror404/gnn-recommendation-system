{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NEWS RECOMMENDATION USING GNN"
      ],
      "metadata": {
        "id": "9a7hPZtvp-hh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🟢 Step 1: Set Up the Environment In your first cell, install the required libraries:"
      ],
      "metadata": {
        "id": "OxKJkb1-oIBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code silently installs PyTorch 2.1.0+cu121, torchvision 0.16.0+cu121, and torchaudio 2.1.0 from the PyTorch cu121 wheel index."
      ],
      "metadata": {
        "id": "0RQO6JPGp6jS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LxL_5xeNn69f"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0 --extra-index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html --timeout=300\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html --timeout=300\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.1.0+cu121.html --timeout=300\n",
        "!pip install -q torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html --timeout=300\n",
        "!pip install -q torch-geometric --timeout=300\n"
      ],
      "metadata": {
        "id": "wx8Agj8mp2Uc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import contextlib, io\n",
        "\n",
        "# Redirect stdout to silence the output\n",
        "with contextlib.redirect_stdout(io.StringIO()):\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"PyTorch Geometric is installed and accessible!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yuG_uF_erNcx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🟢 **Step 2: Create a Toy Dataset**\n",
        "\n",
        "###Create a small dataset that simulates users, news articles, and user–news interactions. In a new cell, paste:"
      ],
      "metadata": {
        "id": "Cu6BE04Erpgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a small list of users.\n",
        "users = ['User0', 'User1', 'User2', 'User3', 'User4']\n",
        "\n",
        "# Create a DataFrame for news articles with news IDs and titles.\n",
        "news = pd.DataFrame({\n",
        "    'news_id': ['News0', 'News1', 'News2', 'News3', 'News4', 'News5', 'News6', 'News7', 'News8', 'News9'],\n",
        "    'title': [\n",
        "        \"Economic Growth in 2025\",\n",
        "        \"New Advances in AI\",\n",
        "        \"Global Warming Trends\",\n",
        "        \"Political Shifts Worldwide\",\n",
        "        \"Sports Update: Finals\",\n",
        "        \"Innovative Startups to Watch\",\n",
        "        \"Health: New Breakthroughs\",\n",
        "        \"Tech Gadgets of Tomorrow\",\n",
        "        \"Art and Culture Trends\",\n",
        "        \"Local News: Community Events\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Create a DataFrame to represent interactions,\n",
        "# where each row indicates that a user interacted with a specific news article.\n",
        "interactions = pd.DataFrame({\n",
        "    'user_id': ['User0', 'User0', 'User1', 'User1', 'User2', 'User3', 'User3', 'User4', 'User4', 'User4'],\n",
        "    'news_id': ['News0', 'News1', 'News1', 'News2', 'News3', 'News0', 'News4', 'News2', 'News6', 'News9']\n",
        "})\n",
        "\n",
        "# Display the dataset to verify its contents.\n",
        "print(\"Users:\")\n",
        "print(users)\n",
        "print(\"\\nNews Articles:\")\n",
        "print(news)\n",
        "print(\"\\nUser Interactions:\")\n",
        "print(interactions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HljCjdQIrxvG",
        "outputId": "fcdfc7c4-0670-4329-97ee-922dc621c5bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users:\n",
            "['User0', 'User1', 'User2', 'User3', 'User4']\n",
            "\n",
            "News Articles:\n",
            "  news_id                         title\n",
            "0   News0       Economic Growth in 2025\n",
            "1   News1            New Advances in AI\n",
            "2   News2         Global Warming Trends\n",
            "3   News3    Political Shifts Worldwide\n",
            "4   News4         Sports Update: Finals\n",
            "5   News5  Innovative Startups to Watch\n",
            "6   News6     Health: New Breakthroughs\n",
            "7   News7      Tech Gadgets of Tomorrow\n",
            "8   News8        Art and Culture Trends\n",
            "9   News9  Local News: Community Events\n",
            "\n",
            "User Interactions:\n",
            "  user_id news_id\n",
            "0   User0   News0\n",
            "1   User0   News1\n",
            "2   User1   News1\n",
            "3   User1   News2\n",
            "4   User2   News3\n",
            "5   User3   News0\n",
            "6   User3   News4\n",
            "7   User4   News2\n",
            "8   User4   News6\n",
            "9   User4   News9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 **Step 3: Preprocess News Titles with GloVe**\n",
        "\n",
        "##We now download small (50-dimensional) GloVe embeddings, load them, and convert each news title into a numeric vector by averaging word embeddings."
      ],
      "metadata": {
        "id": "BWciZqxytUnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.A – Download and Load GloVe Embeddings"
      ],
      "metadata": {
        "id": "U69RAWHUtZNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Create a directory for GloVe if not already present\n",
        "if not os.path.exists('.glove'):\n",
        "    os.makedirs('.glove')\n",
        "\n",
        "# Download the 50D GloVe embeddings\n",
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip -P .glove\n",
        "!unzip -o -q .glove/glove.6B.zip -d .glove\n"
      ],
      "metadata": {
        "id": "jeEIm_CRtb8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29e965d-6560-44ad-b7f8-95381ef907da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open .glove/glove.6B.zip, .glove/glove.6B.zip.zip or .glove/glove.6B.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.B – Convert News Titles to Embeddings"
      ],
      "metadata": {
        "id": "7nXdMFvKvluF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix any broken versions\n",
        "!pip install --upgrade --force-reinstall scipy gensim\n",
        "\n",
        "# Now try again\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_embeddings = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "print(f\"Loaded {len(glove_embeddings)} GloVe vectors.\")\n",
        "print(\"Example:\", glove_embeddings['king'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "zUroCbsU6q9d",
        "outputId": "860c41a4-1db5-474f-a5e4-c681b7e793d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy\n",
            "  Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.5,>=1.23.5 (from scipy)\n",
            "  Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "dc101024f0db49cd89f79a208d551982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "Loaded 400000 GloVe vectors.\n",
            "Example: [ 0.50451   0.68607  -0.59517  -0.022801  0.60046 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.C Convert Titles to Embeddings"
      ],
      "metadata": {
        "id": "qFEnoS4QvzMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def title_to_embedding(title, embeddings_dict, embedding_dim=50):\n",
        "    # Tokenize: lowercase and extract words using regex\n",
        "    tokens = re.findall(r'\\b\\w+\\b', title.lower())\n",
        "    valid_vectors = [embeddings_dict[token] for token in tokens if token in embeddings_dict]\n",
        "\n",
        "    if valid_vectors:\n",
        "        return np.mean(valid_vectors, axis=0)  # average the word vectors\n",
        "    else:\n",
        "        return np.zeros(embedding_dim, dtype='float32')  # fallback if no valid token\n",
        "\n",
        "# Apply this function to each news title\n",
        "news['embedding'] = news['title'].apply(lambda x: title_to_embedding(x, glove_embeddings))\n",
        "\n",
        "# Inspect the result\n",
        "print(news[['news_id', 'title', 'embedding']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYTAgJoZv463",
        "outputId": "c33c4be3-b0a6-43dc-acfe-ebdad3482d18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  news_id                       title  \\\n",
            "0   News0     Economic Growth in 2025   \n",
            "1   News1          New Advances in AI   \n",
            "2   News2       Global Warming Trends   \n",
            "3   News3  Political Shifts Worldwide   \n",
            "4   News4       Sports Update: Finals   \n",
            "\n",
            "                                           embedding  \n",
            "0  [0.36180013, 0.21652225, 0.3831025, -0.2690132...  \n",
            "1  [0.07600999, 0.03465251, -0.009784758, 0.30647...  \n",
            "2  [0.064313345, 0.4191023, 0.26325163, -0.171656...  \n",
            "3  [0.26426998, 0.020493334, 0.09324334, -0.13158...  \n",
            "4  [-0.7301367, 0.7985837, -0.00303333, 1.28415, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 Step 4: Build the Bipartite Graph Using PyTorch Geometric"
      ],
      "metadata": {
        "id": "wyJIP8aOw2OP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.A – Map Node IDs to Indices"
      ],
      "metadata": {
        "id": "CevszB1fxUAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Map each user to a numerical index\n",
        "user_to_index = {user: idx for idx, user in enumerate(users)}\n",
        "\n",
        "# Extract all news IDs from the news DataFrame\n",
        "all_news_ids = news['news_id'].tolist()\n",
        "news_to_index = {nid: idx for idx, nid in enumerate(all_news_ids)}\n",
        "\n",
        "num_users = len(users)\n",
        "num_news = len(all_news_ids)\n",
        "total_nodes = num_users + num_news"
      ],
      "metadata": {
        "id": "k-BbZhLCxW4P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.B – Create Node Features"
      ],
      "metadata": {
        "id": "VyYmYHpmxcHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- USER NODE FEATURES ---\n",
        "# One-hot embedding for each user. Shape: [num_users, num_users]\n",
        "user_features = np.eye(num_users, dtype=np.float32)\n",
        "\n",
        "# We pad from [num_users, num_users] to [num_users, 50]\n",
        "if user_features.shape[1] < 50:\n",
        "    pad_size = 50 - user_features.shape[1]\n",
        "    user_features = np.pad(user_features, ((0, 0), (0, pad_size)), 'constant', constant_values=0)\n",
        "\n",
        "# Convert user_features to a Torch tensor\n",
        "x_users = torch.tensor(user_features, dtype=torch.float)  # shape: [num_users, 50]\n",
        "\n",
        "# --- NEWS NODE FEATURES ---\n",
        "# Stack the 50D embeddings from the news DataFrame\n",
        "news_embeds = np.vstack(news['embedding'].values).astype(np.float32)  # shape: [num_news, 50]\n",
        "x_news = torch.tensor(news_embeds, dtype=torch.float)\n",
        "\n",
        "# Combine user and news features into a single feature matrix\n",
        "x = torch.cat([x_users, x_news], dim=0)  # shape: [num_users + num_news, 50]\n",
        "\n",
        "print(\"Combined feature matrix shape:\", x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk8tpY8HxZsS",
        "outputId": "9e2a9b4a-c812-4305-b0c8-a53fbeab7563"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined feature matrix shape: torch.Size([15, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.C – Build the Edges\n"
      ],
      "metadata": {
        "id": "dP5NBu3Txgaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges_src = []\n",
        "edges_dst = []\n",
        "\n",
        "for _, row in interactions.iterrows():\n",
        "    u_idx = user_to_index[row['user_id']]\n",
        "    n_idx = news_to_index[row['news_id']] + num_users  # offset for news\n",
        "    # Add undirected edges\n",
        "    edges_src.extend([u_idx, n_idx])\n",
        "    edges_dst.extend([n_idx, u_idx])\n",
        "\n",
        "edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)  # shape: [2, num_edges]\n",
        "\n",
        "print(\"Edge index shape:\", edge_index.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33SmGY5OxgGr",
        "outputId": "25734813-7379-4847-ec2c-68d21b0fd47c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge index shape: torch.Size([2, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.D – Create the PyG Data Object"
      ],
      "metadata": {
        "id": "PvhGFmhFxoVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Data(x=x, edge_index=edge_index)\n",
        "print(\"Number of nodes:\", data.num_nodes)\n",
        "print(\"Node feature shape:\", data.x.size())\n",
        "print(\"Number of edges:\", data.num_edges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sMdlmI1xrA1",
        "outputId": "505c307c-d8f8-43fd-ff5e-45f745486c9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 15\n",
            "Node feature shape: torch.Size([15, 50])\n",
            "Number of edges: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 Step 5: Define a Simple GCN Model"
      ],
      "metadata": {
        "id": "YUpfHCXsx1fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Define a simple 2-layer GCN model.\n",
        "class SimpleGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        # First GCN layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        # Second GCN layer to produce final embeddings\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # Apply first convolution and non-linearity.\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        # Apply second convolution.\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model:\n",
        "# Input features: 50 (from our node features)\n",
        "# Hidden dimension: 32 (arbitrarily chosen for this toy project)\n",
        "# Output embedding dimension: 16 (this is the dimension of the learned embeddings)\n",
        "model = SimpleGCN(in_channels=50, hidden_channels=32, out_channels=16)\n",
        "\n",
        "# Print the model summary\n",
        "print(model)\n",
        "\n",
        "# Run a forward pass using our graph data (data from Step 4)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output_embeddings = model(data)\n",
        "    print(\"Output embeddings shape:\", output_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2PZfKXRx4Eh",
        "outputId": "1695c380-49bd-407a-8178-665f11ce1436"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleGCN(\n",
            "  (conv1): GCNConv(50, 32)\n",
            "  (conv2): GCNConv(32, 16)\n",
            ")\n",
            "Output embeddings shape: torch.Size([15, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 Step 6: Train the GNN for Interaction Prediction"
      ],
      "metadata": {
        "id": "YyB0LIJpyIgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# STEP 6.A: Prepare the Training Data\n",
        "\n",
        "# Build a list of positive edges: each is a tuple (user_index, news_index)\n",
        "positive_edges = []\n",
        "for _, row in interactions.iterrows():\n",
        "    user_idx = user_to_index[row['user_id']]\n",
        "    news_idx = news_to_index[row['news_id']] + num_users  # offset for news nodes\n",
        "    positive_edges.append((user_idx, news_idx))\n",
        "\n",
        "# Function for negative sampling:\n",
        "def sample_negative_edges(num_samples):\n",
        "    neg_edges = []\n",
        "    while len(neg_edges) < num_samples:\n",
        "        # Randomly select a user and a news article\n",
        "        u = random.randrange(0, num_users)\n",
        "        n = random.randrange(0, num_news) + num_users  # offset for news\n",
        "        # Only add if this (user, news) edge doesn't exist in positive_edges\n",
        "        if (u, n) not in positive_edges:\n",
        "            neg_edges.append((u, n))\n",
        "    return neg_edges\n",
        "\n",
        "num_positive = len(positive_edges)\n",
        "negative_edges = sample_negative_edges(num_positive)\n",
        "\n",
        "# Helper function: get dot-product scores for a list of edges.\n",
        "def get_edge_scores(embeddings, edge_list):\n",
        "    scores = []\n",
        "    for (u_idx, n_idx) in edge_list:\n",
        "        # Dot product between user and news embeddings.\n",
        "        score = torch.dot(embeddings[u_idx], embeddings[n_idx])\n",
        "        scores.append(score)\n",
        "    return torch.stack(scores)\n",
        "\n",
        "# STEP 6.B: Training Loop\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 200  # You can adjust the epochs as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Compute all node embeddings with a forward pass\n",
        "    embeddings = model(data)  # shape: [total_nodes, out_channels] i.e., [15, 16]\n",
        "\n",
        "    # Get scores for both positive and negative samples\n",
        "    pos_scores = get_edge_scores(embeddings, positive_edges)\n",
        "    neg_scores = get_edge_scores(embeddings, negative_edges)\n",
        "\n",
        "    # Create labels: positive = 1, negative = 0\n",
        "    pos_labels = torch.ones(pos_scores.size(0))\n",
        "    neg_labels = torch.zeros(neg_scores.size(0))\n",
        "\n",
        "    # Concatenate scores and labels\n",
        "    all_scores = torch.cat([pos_scores, neg_scores])\n",
        "    all_labels = torch.cat([pos_labels, neg_labels])\n",
        "\n",
        "    # Compute Binary Cross Entropy Loss (with logits)\n",
        "    loss = F.binary_cross_entropy_with_logits(all_scores, all_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSPbW66myUYf",
        "outputId": "f79d766c-b886-44cd-9ddc-d462f6936286"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/200, Loss: 0.0715\n",
            "Epoch 40/200, Loss: 0.0003\n",
            "Epoch 60/200, Loss: 0.0000\n",
            "Epoch 80/200, Loss: 0.0000\n",
            "Epoch 100/200, Loss: 0.0000\n",
            "Epoch 120/200, Loss: 0.0000\n",
            "Epoch 140/200, Loss: 0.0000\n",
            "Epoch 160/200, Loss: 0.0000\n",
            "Epoch 180/200, Loss: 0.0000\n",
            "Epoch 200/200, Loss: 0.0000\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 Step 7: Generate Recommendations"
      ],
      "metadata": {
        "id": "VVHJx-2hyrDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_user(user_id, top_k=3):\n",
        "    # Basic checks to ensure required variables exist in the current scope\n",
        "    required_vars = ['data', 'model', 'user_to_index', 'num_users', 'num_news', 'news']\n",
        "    missing_vars = [var for var in required_vars if var not in globals()]\n",
        "    if missing_vars:\n",
        "        print(\"The following variables are missing. Please run previous steps:\", missing_vars)\n",
        "        return None\n",
        "\n",
        "    # Check if user_id is in user_to_index:\n",
        "    if user_id not in user_to_index:\n",
        "        print(f\"User '{user_id}' not found in user_to_index.\")\n",
        "        return None\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation.\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Run a forward pass to obtain the node embeddings.\n",
        "        embeddings = model(data)\n",
        "\n",
        "    # Extract the user's embedding\n",
        "    user_idx = user_to_index[user_id]\n",
        "    user_embedding = embeddings[user_idx]  # shape: [16]\n",
        "\n",
        "    # Extract the news embeddings\n",
        "    news_embeddings = embeddings[num_users : num_users + num_news]  # shape: [num_news, 16]\n",
        "\n",
        "    # Calculate dot product scores between the user's embedding and each news embedding (still on GPU or CPU).\n",
        "    scores = torch.matmul(news_embeddings, user_embedding)  # shape: [num_news]\n",
        "\n",
        "    # Use torch.topk to get top-k indices (no NumPy call).\n",
        "    top_values, top_indices = torch.topk(scores, top_k)  # both are Tensors\n",
        "\n",
        "    # Get the corresponding news IDs from the news DataFrame\n",
        "    news_ids = news['news_id'].tolist()\n",
        "\n",
        "    # Build recommendation list\n",
        "    # Convert each score to a Python float using .item()\n",
        "    recommended_news = []\n",
        "    for i, idx in enumerate(top_indices):\n",
        "        news_index = idx.item()\n",
        "        recommended_news.append((news_ids[news_index], top_values[i].item()))\n",
        "\n",
        "    return recommended_news\n",
        "\n",
        "# Example usage\n",
        "recommendations = recommend_for_user('User0', top_k=3)\n",
        "if recommendations is not None:\n",
        "    print(\"Recommendations for User0:\", recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fbP80qysWP",
        "outputId": "89da6b66-cf50-4b11-ce85-204de2c6d937"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for User0: [('News8', 28.454833984375), ('News1', 27.753583908081055), ('News0', 14.280116081237793)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🟢 Step 8: Build a Simple UI with Gradio"
      ],
      "metadata": {
        "id": "vdjVCrck2TJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade gradio\n"
      ],
      "metadata": {
        "id": "PvHAkJaR2Szm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b8558e-2853-49c6-8ec3-81537254a705"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# ✅ User and City keys (file paths no longer needed here)\n",
        "user_images = {\n",
        "    \"User0\": None,\n",
        "    \"User1\": None,\n",
        "    \"User2\": None,\n",
        "    \"User3\": None,\n",
        "    \"User4\": None,\n",
        "}\n",
        "\n",
        "city_images = {\n",
        "    \"Delhi\": None,\n",
        "    \"Mumbai\": None,\n",
        "    \"Pune\": None,\n",
        "    \"Bangalore\": None,\n",
        "    \"Srinagar\": None,\n",
        "}\n",
        "\n",
        "time_slots = [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"]\n",
        "\n",
        "# ✅ Output function connected to GNN\n",
        "def display_output(user, time_of_day, city):\n",
        "    try:\n",
        "        recommendations = recommend_for_user(user, top_k=3)\n",
        "        if recommendations is None:\n",
        "            return \"⚠️ Recommendation system not ready. Please check your model.\"\n",
        "        result = f\"📍 City: {city} | 🕒 Time: {time_of_day}\\n\\n\"\n",
        "        result += \"\\n\".join([f\"📰 {news_id} — Score: {score:.2f}\" for news_id, score in recommendations])\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error: {str(e)}\"\n",
        "\n",
        "# ✅ Build the Gradio UI\n",
        "with gr.Blocks(\n",
        "    css=\"\"\"\n",
        "        body {\n",
        "            background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);\n",
        "        }\n",
        "        .gr-button {\n",
        "            background: linear-gradient(to right, #667eea, #764ba2) !important;\n",
        "            color: white !important;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        h1, h2, label {\n",
        "            color: white !important;\n",
        "        }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "    gr.Markdown(\"## 🌙 GNN-Based News Recommender\")\n",
        "\n",
        "    # 👤 User selection\n",
        "    gr.Markdown(\"### 👤 Select a User\")\n",
        "    with gr.Row():\n",
        "        user_choice = gr.Radio(choices=list(user_images.keys()), label=\"Select User\")\n",
        "\n",
        "    with gr.Row():\n",
        "        for name in user_images.keys():\n",
        "            gr.Image(\n",
        "                label=f\"Upload {name} Image\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "    # 🕒 Time of Day\n",
        "    gr.Markdown(\"### 🕓 Select Time of Day\")\n",
        "    time_input = gr.Dropdown(choices=time_slots, label=\"Time of Day\", value=\"Night\")\n",
        "\n",
        "    # 🏙️ City selection\n",
        "    gr.Markdown(\"### 🏙️ Select a City\")\n",
        "    with gr.Row():\n",
        "        city_choice = gr.Radio(choices=list(city_images.keys()), label=\"City\")\n",
        "\n",
        "    with gr.Row():\n",
        "        for name in city_images.keys():\n",
        "            gr.Image(\n",
        "                label=f\"Upload {name} Image\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "    # 🎯 Submit and Output\n",
        "    gr.Markdown(\"### ✅ Get Recommendations\")\n",
        "    submit = gr.Button(\"🎬 Get Recommendations\")\n",
        "    output = gr.Textbox(label=\"📦 Output\", lines=5)\n",
        "\n",
        "    submit.click(fn=display_output, inputs=[user_choice, time_input, city_choice], outputs=output)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "sQzKZI9U35mF",
        "outputId": "9528d616-ad3a-4f03-8faf-57d874e56e6e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f73ff0ff121edba1c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f73ff0ff121edba1c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMW-l8Huofi2"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}